%----------------------------------------------------------------------------
\chapter{Overview of the Approach}
%----------------------------------------------------------------------------
In this chapter, the various aspects of the proposed approach are detailed. In Section \ref{sec_methodology}, the application of this methodology from the users' point of view: how are they supposed to interact with the interactive automata learning framework and how can they utilize it to design reactive systems in a declarative way. Then, in Section \ref{sec_architecture}, the applied software architecture, software components, algorithms and data structures are presented in the following order: first, the components concerned with the automata learning algorithm, then those responsible for its interaction with the oracle, then the possible interactions of the oracle with the engineer.
%----------------------------------------------------------------------------
\section{Overview of the Methodology} \label{sec_methodology}
%----------------------------------------------------------------------------
\begin{figure}[!ht] 
	\centering
	\fbox{
		\includegraphics[width=150mm, keepaspectratio]{figures/methodology_interactiontypes.png}
	}
	\caption{Possibilities of the Engineer} %TODO title 
	\label{fig_methodology_interactiontypes}
\end{figure}

Our methodology is heavily based on the interaction of the user with the system, especially its \textit{Oracle} component. The different types of interaciton are summarized on Figure \ref{fig_methodology_interactiontypes} and elaborated on in Subsection \ref{subs_reqtypes}. These interactions take place in a predefined order - the \textit{proposed workflow}, illustrated on Figure \ref{fig_methodology_workflow}. This workflow consists of two phases: first, an \textit{offline} one, and then an \textit{online} one. During the offline phase, the system offers little assistance, the designing engineer must determine the required details by other means. The interactive system design happens during the online phase. 

The individual steps in both the offline and the online phases have a predefined syntax with the corresponding, precisely defined semantics. Their common feature is the declarative way of describing the system components, which allows the engineer to focus solely on the expected behavior and acquire a minimal model exhibiting the specified functionality. The following subsections explain these steps in detail.

\begin{figure}[!ht] 
	\centering
	\fbox{
		\includegraphics[width=150mm, keepaspectratio]{figures/methodology_workflow.png}
	}
	\caption{The Proposed Workflow} %TODO title 
	\label{fig_methodology_workflow}
\end{figure}
%TODO fork a komponenseknek
%TODO bekeretezni az online és az offline részeket, meg feliratozni

%---------------------------------------------------------------
\subsection{Component and Interface Definition} \label{subs_compdef}
%---------------------------------------------------------------
%megadhat több komponenst, névvel, ezek a megfelelő viselkedéseket fogják tanúsítani. I/O ábécét megadjuk előre, komponensek kapcsolatát a nevekből inferáljuk. Mindegyiket TELJESEN KÜLÖN tanuljuk (fork). Ezért egyelőre semmit sem garantálunk ilyen téren, de előnyei is vannak.
The first step of the workflow is the declaration of the system components. This happens in the offline phase, as the determination of the system components, their exact boundaries and interfaces is out of the scope of this work. Nonetheless, the engineer must provide the names of the system components, along with their interfaces - in other words their input- and output alphabets - before the workflow can proceed to the next step.

Users are encouraged to specify input and output characters qualified with interface names in the format 'Port.character', as this supplies the subsequent steps with essential information about the connections of the individual system components.

The components are handled as independent systems in every other aspect. This results - among others - in the arbitrary ordering of the online behavior-learning phases, and the behavioral faults being limited to their components of origin (although this does not limit the propagation of errors through messages resulting from incorrect behavior).
The syntax of component and interface definitions is quite simple, as illustrated in Listing \ref{lst_compdef}.

\bigskip
\begin{lstlisting} [language=tex,caption=Example of a component declaration along with its interfaces,label=lst_compdef]
	TODO EXAMPLE
\end{lstlisting} %TODO

%---------------------------------------------------------------
\subsection{Requirement Types} \label{subs_reqtypes}
%---------------------------------------------------------------
During the workflow, the engineers can provide requirements in both the online and the offline phases. 

In the offline phase, this means that they add requirements they have formulated in advance. This is useful for more general requirements, with the scope of the whole component, conveniently formulated by program logic expressions, or long and complex traces.

In the online phase, adding requirements means answering the questions formulated by the algorithm about a yet unspecified behavior at a specific place in the trace currently being examined. This too can be answered through program logic - e.g. when the engineer realizes a general property during the model construction - but also through traces and through giving the corresponding output directly.

\textbf{Corresponding Output}
% TODO ref background: trace(-based)

This is the simplest way of specifying the behavior of the system, also containing the least amount of information among the different model types. To put simply, this means giving the output for a given input sequence, without any additional information. This supposedly answers the question of the <system> at \textit{one} given point, and that is the end of its scope.

Examples of corresponding output specification can be seen in Listing \ref{lst_iopair}.

\bigskip
\begin{lstlisting} [language=tex,caption=Examples of corresponding output specification,label=lst_iopair]
Offline: 
>input1 input2 input3 output

Online: 
>Output for [input1 input2 input3]:
>output3

(assuming input1/2/3 are from the input alphabet and output3 is from the output alphabet)
\end{lstlisting}

\textbf{Valid Trace}

Valid traces are a more complex form of specifying the corresponding output: it gives the corresponding output for any prefix of the contained input sequence. This might be useful, as usually the whole output sequence is taken into consideration when determining the output for some inputs. Thus, the <system> can get \textit{multiple} answers concerning the behaviors in question.

An example can be seen in Listing \ref{lst_validtrace}.

\bigskip
\begin{lstlisting} [language=tex,caption=Example of a valid trace,label=lst_validtrace]
Both offline and online:
>input1/output1 input2/output2 input3/output3

(assuming input1/2/3 are from the input alphabet and output1/2/3 are from the output alphabet) 
\end{lstlisting}

\textbf{Sequence Diagram}
%TODO ref backgr UML

UML-like sequence diagrams are an even more complex form of trace-based models, as they can contain several traces - due to them having \textit{alt} and \textit{opt} fragments for branching the behavior. They also have - among others - \textit{ref} fragments for referencing behaviors specified elsewhere.

Sequence diagrams can also be used to model infinite behavior, which results in containing plenty of information, which in turn results in possibly answering \textit{several} questions formulated by the <system>.

%TODO
An example for the application of sequence diagrams can be seen on [TODO insert example]

It is important to note, that the specification and integration of sequence diagrams into this framework is not yet complete. 

\textbf{Trace to Exclude}

Invalid traces are similar to valid traces, with the difference that the contained behavior must not appear in the resulting model. They are most useful for small output alphabets, or when the range of possible behaviors is otherwise contained - e.g. through program logic expressions or several other excluded traces.

They can also be used to formulate requirements even when the determination of the correct behavior does not directly follow from them: when specifying the behavior in question, the <system> will signal any conflicting requirements for the examined input sequences and require the user to remove one - thus facilitating the enforcement of these requirements too.

An example for invalid traces can be seen in Listing \ref{lst_invalidtrace}.

\bigskip
\begin{lstlisting} [language=tex,caption=Example of a trace to exclude,label=lst_invalidtrace]
Both offline and online:
>input4/output4 input5/output5

(assuming input4/5 are from the input alphabet and output4/5 are from the output alphabet) 
\end{lstlisting}

\textbf{LTL Expression}
%TODO ref backgr LTL
%TODO ref backgr LTS

LTL expressions are a highly complex type of program logic-based requirement specification: they can be used to formulate propositional logic expressions with temporal connectives over \textit{paths} of a \textit{base model}, as described in [TODO ref backgr]. 

For our application, we introduce our own LTL expression language with its own syntax and semantics - although attempting to keep it similar to other generally known variants, especially that of SPOT [TODO cite]. The full syntax of the LTL expressions - also determining the operator precedence - can be seen in Listing \ref{lst_ltlfullsyntax}.

The base model of the LTL expressions is the LTS [TODO ref backgr] interpretation of the component under learning. This means, that the set of atomic propositions that can be used in these expressions are the possible labels of the transitions, which are the elements of the input and the output alphabets of the component. The model synthesis takes place assuming event semantics - exactly one input and one output event happening at any given time. For this reason, we also introduced these semantics to the LTL expressions: the conjunction of exactly one input and one output character must hold at any given point in time for it to be considered correct - and every other character must be negated at the same point. This also entails, that given another character not explicitly negated at that point, it is assumed to be automatically negated, and in the case that no proposition is declared explicitly to hold, it is assumed that either one of the non-explicitly negated characters hold. 

The semantics of the supported temporal connectives, and other aspects of the LTL semantics in general, are similar to those described in [TODO ref backgr] %TODO

Examples for a valid LTL expressions can be seen in Listing \ref{lst_ltlex}.

\bigskip
\begin{lstlisting} [language=tex,caption=Examples of LTL expressions,label=lst_ltlex]
Assuming Control.interrupt and toggle are from the input alphabet and blinkingYellow is from the output alphabet, both offline and online:
>F(interrupt -> X(G(toggle) -> G(blinkingYellow)))

Assuming the output alphabet also contains red, yellow and green, it is equivalent to:
>F(interrupt&!toggle -> X(G(toggle&!interrupt) -> G(blinkingYellow&!red&!yellow&!green)))
\end{lstlisting}

It is important to note, that the specification of our LTL variant is not yet complete: for the compactness of requirement specifications it would make sense to integrate additional well-known boolean operators - like XOR (exclusive-or) - and temportal connectives - such as WB (weak-before) and R (release) - into the language. 

%---------------------------------------------------------------
\subsection{Conflicting Requirements} \label{subs_conf}
%---------------------------------------------------------------
The requirements the designing engineer provides the <system> with may easily be conflicting, especially in case of LTL expressions and invalid traces - that describe possibly infinite sets of behaviors. For this reason, it is essential for the system to provide some kind of conflict handling within the practical boundaries of the available resources. 

The whole problem is a difficult and resource intensive task for reasons discussed later. Consequently, the <system> only guarantees to handle the conflict, when it appears for other reasons too. In that case, the user is asked to remove one of the conflicting models, before the analysis of the behavior can proceed.

As conflicts only become apparent during the online phase of the workflow, the conflict handling is only present there. However, conflicts that were added to <the system> earlier are also discovered and resolved in that phase. An example of a requirement conflict handling can be seen in Listing \ref{lst_conflicthandling}.

\bigskip
\begin{lstlisting} [language=tex,caption=Example of a requirement conflict handling,label=lst_conflicthandling]
	TODO EXAMPLE
\end{lstlisting}%TODO

%---------------------------------------------------------------
\subsection{Checking the Correctness of the Synthesized Model} \label{subs_eq}
%---------------------------------------------------------------
During the online phase, whenever <the system> assumes that it has gathered enough information to construct a model for the given component, the engineer if offered with a possible model representing the current state of the model synthesis - the equivalent of an equivalence query in automaton learning algorithms. This model can either be approved, or a counterexample is required from the user, where the model does not meet the - not yet specified - requirements.

%TODO az EQ modell tulajdonságai?

If the model is accepted, the workflow can attempt to proceed to the next step - the serialization of the model. If a counterexample is provided, the online phase resumes and the system design continues until the next possible model is reached.

Example of models offered in equivalence queries can be seen on Figure \ref{fig_methodology_eqex}.

\begin{figure}[!ht] 
	\centering
	\fbox{
		\includegraphics[height=50mm, keepaspectratio]{figures/methodology_eqex1.png}
	}
	\fbox{
		\includegraphics[height=50mm, keepaspectratio]{figures/methodology_eqex2.png}
	}
	\caption{Examples of \textit{equivalence queries}} %TODO title 
	\label{fig_methodology_eqex}
\end{figure}

%---------------------------------------------------------------
\subsection{The Resulting System Model} \label{subs_resultingmodel}
%---------------------------------------------------------------
%TODO ha minden kész, valid Gammát kapunk, ezt:
% kiegészíthetjük
% generálhatunk belőle akármit, amit a gamma tud (ref backgr)
When each of the component models declared during the first step of the workflow are completed, the resulting system model can be serialized and handed over to the engineer for further extensions or to use it for any of its possible applications. This serialization can happen in various formalisms.

%TODO ref 
One such possible formalism is the serialization to a Gamma statechart, introduced in [TODO ref backgr]. Gamma statecharts are high-level state-based models, to which every functionality offered by the Gamma Statechart Composition Framework can be applied. Our framework offers full-scale Gamma serialization: when choosing this formalism, a whole project will be created, along with interface definitions, component definitions - for each of the previously declared components, with the synthesized behavior - and a composite system definition, connecting the components based on the names of their interfaces.

%TODO ref
Another possibility is the serialization to the Mealy machine formalism of the framework - as presented when checking the correctness of the model. This results in a lower-level set of independent model, with a completely different set of applications.

%----------------------------------------------------------------------------
\section{Overview of the Architecture} \label{sec_architecture}
%----------------------------------------------------------------------------